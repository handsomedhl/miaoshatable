# springboot内嵌tomcat并发线程数参数调优

将项目部署到云上后，使用jmeter进行性能压测发现瓶颈

```shell
#查看程序支持的线程数
pstree -p 19826 | wc -l
```

![](images/QQ截图20200928171639.png)

重要的参数：

server.tomcat.accept-count:等待队列长度，默认100
server.tomcat.max-connections:最大可被连接数，默认10000
server.tomcat.max-threads:最大工作线程数，默认200
server.tomcat.min-spare-threads:最小工作线程数，默认10





## 对我们的程序进行线程进行扩容，线程池进行变更

```shell
server.tomcat.accept-count=1000
server.tomcat.max-threads=400
server.tomcat.min-spare-threads=100#一般我们配置点不会太低，是为了应对突发的流量问题，让操作系统有充足的时间进行反应

```

server.tomcat.max-threads并不是越多越好，超过一定的阈值后，将花费大量的时间在cpu的调度上。



进行参数优化之后，tomcat的线程数上来了

![](images/QQ截图20200928172524.png)



## 对keepAlive进行优化

为什么要对keepAlive进行优化？

keepAlive长连接，http1.1后支持的功能，开启后服务器会缓存当次连接，多次请求复用一个连接，当请求量较大时节省了为每个请求创建连接、关闭连接的开销，提高服务器的响应性能。

在springboot中进行配置（服务端的配置）：

```java
/**
 * 描述：
 *  我们在配置文件中配置的参数会被传递到WebServerFactoryCustomizer，我们在WebServerFactoryCustomizer中
 *  进行最后一次修改，对keepAlive进行优化
 * @author hl
 * @version 1.0
 * @date 2020/9/28 19:22
 */
@Component
public class WebServerConfiguration implements WebServerFactoryCustomizer<ConfigurableWebServerFactory> {
    /**
     * 在new出tomcat容器的时候会传给我们对应的一个ConfigurableWebServerFactory factory) ，一个可配置
     * 的WebServer的工厂，我们可以在这里定制化一些东西
     * @param factory
     */
    @Override
    public void customize(ConfigurableWebServerFactory factory) {
        //使用对应的工厂类提供给我们的接口定制化我们的tomcat connector
        ((TomcatServletWebServerFactory)factory).addConnectorCustomizers(connector -> {
            //在这里定制化我们需要的参数
            Http11AprProtocol protocol = (Http11AprProtocol)connector.getProtocolHandler();
            //设置长连接的超时时间，30秒,超时后服务端断开连接
            protocol.setKeepAliveTimeout(30000);
            //设置单次长连接的最大请求数，超过定制的阈值后服务端断开连接
            protocol.setMaxKeepAliveRequests(10000);
        });
    }
}
```



# nginx配置

## openresty安装

openresty是对nginx 的封装，并且支持一些lua脚本的开发

1、下载对应的rpm包进行解压

```shell
tar -zxvf openresty-1.13.6.2.tar.gz 
```

2、安装

```shell
无缝重启#安装需要的环境
yum install pcre-devel openssl-devel gcc curl
#初始化
./configure
#编译
make
#安装
make install
#启动
sbin/nginx -c conf/nginx.conf
#无缝重启
sbin/nginx -s reload
```



location节点path:指定url映射key
location节点内容:root指定location path后对应的根路径,index指定默认的访问页

## nginx配置动静分离，反向代理服务器

在config/nginx.conf中进行配置

```shell
#配置反向代理的服务器
upstream backend_server{
          server 192.168.242.140 weight=1;
          server 192.168.242.141 weight=1;
}
server {
    listen       80;
    server_name  localhost;

    #charset koi8-r;

    #access_log  logs/host.access.log  main;


    location /resources/ {#配置静态资源文件路由
    	#alias表示替换，将alias后面的路径的资源文件作为/resources/路由访问的资源
        alias   /usr/local/openresty/nginx/html/resources/;
        index       index.html ;
    }
    location / {
    	#将路由进行转发
        proxy_pass http://backend_server;
        proxy_set_header Host $http_host:$proxy_port;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}

```

开启tomcat access log日志进行验证，在外挂的配置文件中开启

```properties
server.tomcat.accesslog.enabled=true
server.tomcat.accesslog.directory=/home/miaosha/tomcat
server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D
```

验证是确实是按照我们配置的权重来访问我们的web服务器

![](images/QQ截图20200930194106.png)

## 配置nginx与代理的服务器进行keepAlive

在nginx.conf文件中进行配置

```shell
upstream backend_server{
          server 192.168.242.140 weight=1;
          server 192.168.242.141 weight=1;
          #设置长连接超时时间
          keepalive 30;
}
location / {
                proxy_pass http://backend_server;
                proxy_set_header Host $http_host:$proxy_port;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                #设置http协议的版本为1.1
                proxy_http_version 1.1;
                #http1.1版本下将Connection设为""，默认支持keepAlive，若想关闭则将Connection设为"close"
                proxy_set_header Connection "";
        }


        

```







## nginx高效的原因

### 1、epoll的多路复用

**java bio模型，阻塞进程式**

在网络通信中，客户端想要发送数据到服务端，会发送一个socket.write，java client只有等到socket.write中所有的字节流input到tcp/ip的缓冲区之后，对应的java client才会返回，在网络很慢的时候，如果服务端的tcp/ip的缓冲区被塞满的时候，再有客户端发起socket.write，那么java client就会等待服务端进行处理，直到有tcp/ip的缓冲区的时候，才会直接返回。

![](images/QQ截图20200929192209.png)

**linux select模型，变更触发轮询查找，有1024数量上限**

select多路复用，一个select可以复用上百个或上千个客户端连接，假设java server会监听100个socket-client，在没有变化的时候java server会阻塞自己，当其中某一个或者多个client发生变化的时候，java server会被唤醒，遍历监听的所有连接找到变化的一个或多个，然后执行read操作，此时会会迅速返回java client，因为只有当有资源可以进行读写，才会将java server唤醒。但是每次变更时都会进行遍历操作，影响性能

![](images/QQ截图20200929193116.png)

**epoll模型，变更触发回调直接读取，理论无上限**

在select模型上做了优化，当发生变化时，会直接唤醒自己执行回调函数，不用进行遍历。

linux2.6以上会自动以epoll模型运作。



### 2、master worker进程模型

管理员只与master进程交互。

worker进程处理client的连接，worke进程的数量可以在配置文件中进行配置。worker进程都是单线程的。没有阻塞的情况下，单线程的处理速度是比多线程要快的。worker操作是不允许阻塞的，因为worker单线程中的操作都是进过epoll多路复用之后，明确地告诉它这个句柄上是有可以读的操作，worker上的工作也就是从内核空间到用户空间的数据的拷贝工作而已。

**nginx无缝重启的原理：nginx -s reload**

master与worker进程是属于父子进程的关系，也就是父子进程master可以对子进程的worker的资源进行管理和调配。

当执行无缝重启时，master不会重启，master会回收所有worker线程中的socket句柄，然后重新加载配置文件，根据配置文件new出新的worker进程，再把socket句柄交给新的worker进程，这里的操作都是在内存中瞬时完成，客户端不会感知到变化。



![](images/QQ截图20200929193640.png)

### 3、协程机制

协程是依附于线程的内存模型，是比线程更小的概念，切换开销小，因为是在内存中

遇到阻塞及归还执行权（相当于方法中的return），代码是同步的。

无需进行加锁



# 分布式session

1、作用

分布式系统中需要将session在多个结点之间共享，tomcat自带的session不能满足需求

2、实现原理

​		基于token传输类似sessionid，java代码实现，token也就是我们为每个用户生产的登录凭证，要求时唯一的，可以使用UUID来做，用户登录后，为客户端分发一个唯一token，在一些需要检查登录状态的请求的参数中需要携带上token，**让它作为请求参数的一部分**。在分布式系统中，我们一般会将token放入redis等集中式缓存管理工具中。

​		**为什么不使用cookie？**

​		因为系统可能需要兼容不同的场景，比如：移动端和PC端，在某些情况cookie可能会失效，因此使用token更好，因为它是基于http的

3、步骤

1）导入将session放入redis管理的依赖

```xml
 <!--整合redis-->
    <dependency>
      <groupId>org.springframework.boot</groupId>
      <artifactId>spring-boot-starter-data-redis</artifactId>
    </dependency>
    <!--将session存储到redis中-->
    <dependency>
      <groupId>org.springframework.session</groupId>
      <artifactId>spring-session-data-redis</artifactId>
      <version>2.0.5.RELEASE</version>
    </dependency>
```

2）注入redis的配置类，并开启分布式session

```java
@Component
//开启分布式session，并设置session默认过期时间，单位秒
@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 3600)
public class RedisConfig {
}
```

3）在配置文件中配置redis服务的基本信息

```properties
#配置spring对redis的依赖
spring.redis.host=127.0.0.1
spring.redis.port=6379
spring.redis.database=10

#设置jdies连接池
spring.redis.jedis.pool.max-active=50
spring.redis.jedis.pool.min-idle=20

```

4）在登录成功后将用户信息与生成的token这个键值对存入redis中

5）在需要检查登录状态时，从session中获取token对应的用户信息进行验证

4、token存储在前端的位置

​		前端将token存储在**Window.localStorage**中，只读的`localStorage` 属性允许你访问一个[`Document`](https://developer.mozilla.org/zh-CN/docs/Web/API/Document) 源（origin）的对象 [`Storage`](https://developer.mozilla.org/zh-CN/docs/Web/API/Storage)；存储的数据将保存在浏览器会话中。`localStorage` 类似 [`sessionStorage`](https://developer.mozilla.org/zh-CN/docs/Web/API/Window/sessionStorage)，但其区别在于：存储在 `localStorage` 的数据可以长期保留；而当页面会话结束——也就是说，当页面被关闭时，存储在 `sessionStorage` 的数据会被清除 。

​		应注意，无论数据存储在 `localStorage` 还是 `sessionStorage` ，**它们都特定于页面的协议。**

​		另外，`localStorage` 中的键值对总是以字符串的形式存储。 (需要注意, 和js对象相比, 键值对总是以字符串的形式存储意味着数值类型会自动转化为字符串类型).

# 多级缓存

## 缓存的设计原则

1、用于快速存取设备，最好基于内存

2、将缓存推导离用户最近的地方（离用户越近，锁经过的链路就越短，用户体验越好）

3、脏数据清理（保证缓存数据的一致性，同步更新）

## 多级缓存

### redis集中式缓存

缓存的数据库中间件，因为它具备将数据存储到本地的能力，但是需要容许少量数据的丢失

**单机版**

生成环境不建议使用，有单点故障风险。一旦单台结点出现故障，可能会导致整个服务不可用

**sentinal哨兵模式**

另外引入一台结点redis sentinal（哨兵），会与其他的redis结点保持长连接（心跳机制），它实时地感应到其他redis结点的状态，客户端进行访问时，会向询问redis sentinal可用的redis服务结点，redis sentinal会返回可用的redis结点的信息。客户端获取到信息后再去访问对应的redis结点。

当可用的redis结点信息发生变化的时候，redis sentinal会调整对应的结点关系（主从关系），然后向客户端发送一个change通知，告诉它redis结点发生变化，客户端就会重新想redis sentinal发送请求获取新的结点信息。

![](images/QQ截图20201001144613.png)

**集群cluster模式**

​		sentinal哨兵模式存在缺陷，在水平拓展redis结点的情况下，需要客户端在本地维护分片机制，此时如果需要再继续进行拓展，那么就会有一个数据迁移的过程，这个过程是繁琐的。

集群cluster模式：

​		多个redis结点，redis会自动竞选出master和slave结点，并且集群中的每个redis都和其他多台redis有网状结构，redis能清晰地直到我的主/从是谁，我们其他分片的主从信息，也就是**每个redis结点中都有维护整个集群结构的信息**，这都是基于redis-cluster的数据同步和paxos的竞争算法来实现的。

​		当客户端访问其中的一个结点时，就能获取整个集群结点的信息，并保存到本地。若有结点宕机，集群会自动进行调整更新信息，然后每个结点维护一份新的信息，此时客户端按照旧的集群信息访问到一个不属于新的集群管理范围的key的时候，redis会发送一个reask请求，通知客户端获取新的集群信息

<img src="images/QQ截图20201022151937.png" style="zoom:50%;" />

**项目中使用**

用redis来对商品详情页数据进行缓存，并在controller中接入，让请求不用走下游的server服务，减少对数据的依赖和访问，提高查询的速度

保存商品详情时，java默认的序列化规则不方便我们进行阅读和维护，因此我们需要自定义redis的序列规则，这个操作在我们配置RedisTemplate的时候进行

```java
@Component
//开启分布式session，并设置session默认过期时间，单位秒
@EnableRedisHttpSession(maxInactiveIntervalInSeconds = 3600)
public class RedisConfig {
    @Bean
    public RedisTemplate redisTemplate(RedisConnectionFactory factory){
        RedisTemplate<Object, Object> redisTemplate = new RedisTemplate<>();
        redisTemplate.setConnectionFactory(factory);
        //更改序列化方式
        //key
        StringRedisSerializer stringSerializer = new StringRedisSerializer();
        redisTemplate.setKeySerializer(stringSerializer);
        //value
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
        //添加自定义DateTime格式的数据的序列映射规则
        ObjectMapper mapper = new ObjectMapper();
        SimpleModule simpleModule = new SimpleModule();
        simpleModule.addSerializer(DateTime.class, new JodaDateTimeJsonSerializer());
        simpleModule.addDeserializer(DateTime.class, new JodaDateTimeJsonDeSerializer());
        //使序列化的内容中包含相应的类的信息，转换时可以正确地从json中推断出bean信息
        mapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);

        mapper.registerModule(simpleModule);
        jackson2JsonRedisSerializer.setObjectMapper(mapper);

        redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);

        return redisTemplate;
    }

}
```

DateTime类型的数据需要我们自定义映射的规则

```java
//序列化规则
public class JodaDateTimeJsonSerializer extends JsonSerializer<DateTime> {
    @Override
    public void serialize(DateTime dateTime, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {
        jsonGenerator.writeString(dateTime.toString("yyyy-MM-dd HH:mm:ss"));
    }
}
//反序列化规则
public class JodaDateTimeJsonDeSerializer extends JsonDeserializer<DateTime> {
    @Override
    public DateTime deserialize(JsonParser jsonParser, DeserializationContext deserializationContext) throws IOException, JsonProcessingException {
        String string = jsonParser.readValueAs(String.class);
        DateTimeFormatter formatter = DateTimeFormat.forPattern("yyyy-MM-dd HH:mm:ss");
        return DateTime.parse(string,formatter);
    }
}
```

![](images/QQ截图20201002112905.png)

### 热点数据本地缓存

redis毕竟需要网络开销，并且有集中式负载均衡的性能瓶颈

本地缓存的特点：

- 热点数据
- 脏读不敏感
- 内存可控

本地缓存实际上是缓存在本地的jvm中，jvm的内存时非常宝贵的，因此决定了**本地缓存的数据必须是热点数据**，这样才有价值。并且要**合理地设置热点数据的过期策略**（LRU（当内存不足时，优先淘汰最近少访问的key））。

因为缓存到本地，同步数据到每台机器是十分复杂的，因此，我们一般不同步数据，缓存一些有效期较短的数据，非要同步也是可以实现实现的（消息中间件）。

#### 使用Guava cache

好处：

- 可控制大小和缓存的时间
- 可配置的Lru策略
- 线程安全

步骤：

1）导入Guava cache的依赖

```xml
	 <dependency>
      <!--guava cache本地缓存-->
      <groupId>com.google.guava</groupId>
      <artifactId>guava</artifactId>
      <version>18.0</version>
    </dependency>
```

2）构建一个Cache对象进行缓存的操作

```java
@Service
public class CacheServiceImpl implements CacheService {
    private Cache<String,Object> commonCache = null;

    @PostConstruct
    public void  init(){
        commonCache = CacheBuilder.newBuilder()
                //设置缓存容器的初始容量为10
                .initialCapacity(10)
                //设置缓存中最大可以存储100个key，超过之后，按照lru的策略移除缓存项
                .maximumSize(100)
                //设置缓存过程策略，在写入1分钟后过期
                .expireAfterWrite(1, TimeUnit.MINUTES)
                .build();
    }
    //存取操作......
}
```

![](images/QQ截图20201002145424.png)



### nginx proxy cache缓存

nginx高速磁盘上的缓存。存储在nginx的磁盘上，经过测试，实际效率设置略次于访问经过路由转发后访问redis的效率

```shell
#配置nginx proxy cache的基本信息
proxy_cache_path /usr/local/openresty/nginx/tmp_cache levels=1:2 keys_zone=tmp_cache:100m inactive
=7d max_size=10g;
location  {
    proxy_pass http:/backend_server;
    proxy_cache tmp_cache;
    proxy_cache_key $uri;
    proxy_cache_valid 200 206 304302 7d;
    #proxy_set_header Host $http_host: $proxy_port;
    proxy_set_header Host $http_host;
    proxy_set header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_http_version 1.1;
}
```



### nginx lua缓存

nginx内存缓存，nginx是离客户端最近的结点，因此在它上面做缓存是非常有效的。

特点：

- nginx的每一个worker进程都是在epoll或kqueue这种事件模型之上，封装成协程
- 每一个请求都有一个协程进行处理，之间数据隔离
- lua代码调用io等异步接口时，协程被挂起，上下文数据保持不变。当遇到IO的阻塞，就会向epoll模型中注册，注册完将自己挂起等待epoll模型收到数据返回之后将自己唤醒，还原协程上下文，代码继续执行。代码时同步编写的。



Lua的生命周期：

![](images/QQ截图20201002170256.png)

nginx lua的插载点：

- init_by_lua:系统启动时调用
-  init_worker_by_lua: worker进程启动时调用
-  set_by_lua: nginx变量用复杂lua return
- rewrite_by_lua:重写url规则
- access_by_lua:权限验证阶段
- ==content_by_lua:内容输出节点==（常用的）

#### Shared Dic

Openresty为我们集成了lua脚本的开发的环境（许多定义好的函数库），我们可以直接进行调用，非常方便

shared dic相当于我们之前使用过的guava cache，**共享内存字典，所有worker进程可见，lru淘汰**

使用：

1）声明一个缓存对象my_cache，并配置它的大小,在nginx.conf文件中进行配置

```shell
#http
lua_shared_dict my_cache 128m;
```

2）编写lua脚本定义缓存规则

```lua
-- 存方法
function get_from_cache(key)
        local cache_ngx = ngx.shared.my_cache
        local value = cache_ngx:get(key)
        return value
end
-- 取方法
function set_to_cache(key,value,exptime)
        if not exptime then
                exptime = 0
        end
        local cache_ngx = ngx.shared.my_cache
        local succ,err,forcible = cache_ngx:set(key,value,exptime)
        return succ
end
-- 获取请求中的参数
local args = ngx.req.get_uri_args()
local id = args["id"]
local item_model = get_from_cache("item_"..id)
-- 判断本地是否缓存，如果没有则去下游服务中获取
if item_model == nil then
        local resp = ngx.location.capture("/item/get?id="..id)
        item_model = resp.body
        set_to_cache("item_"..id,item_model,1*60)
end
-- 下一次直接从本地缓存中拿
ngx.say(item_model)

```

3）nginx.conf文件中定义路由规则，指定我们定义的lua脚本

```shell
location /luaitem/get{
                default_type "application/json";
                content_by_lua_file ../lua/itemsharedic.lua;
}
```

JMETER压测结果：

![](images/QQ截图20201003085708.png)



#### redis支持

通过lua脚本，使nginx直接访问redis（从库）。将nginx的压力转移到redis中，让redis分摊更多的压力。

步骤：

1）编写lua脚本

```lua
--获取请求中的参数
local args = ngx.req.get_uri_args()
local id = args["id"]
--导入openresty提供的redis的函数库
local redis = require "resty.redis"
local cache = redis:new()
--建立与redis的连接
local ok,err = cache:connect("192.168.242.133",6379)
local item_mode = cache:get("item_"..id)
if item_model == ngx.null or item_model == nil then
        local resp = ngx.location.capture("/item/get?id="..id)
        item_model = resp.body
    	--这里不用执行set到redis的操作，因为我们的java代码中执行了该操作
end
ngx.say(item_model)
```

2）在nginx.conf的对应路由中进行配置

```shell
location /luaitem/get{
                default_type "application/json";
                content_by_lua_file ../lua/itemredis.lua;
}
```

JMeter测试

![](images/QQ截图20201003095510.png)

### 总结：

缓存架构图：

![](images/QQ截图20201003095251.png)

我们可以发现：

​		性能最高的就是将缓存推到离用户最近的地方，比如nginx本地lua缓存、tomcat本地缓存（guava cache），但同时需要注意的是，换来的代价是占用更多的系统分布式的资源，以及更不容易被更新。需要脏读忍受的控制，更新策略的控制



​		**越接近存储层，越容易实现数据的集中式管理，但是也是性能最差的；越往上占用的系统资源越昂贵，并且对应的更新机制越难，但是性能也越高**，因此并没有一个通用的方法，我们需要针对**==更新策略、对应的缓存热点程度、脏读在业务上的忍受程度==**这几个方面进行综合的考虑

# 页面静态化

## 静态资源CDN

​		CDN内容分发网络，依靠部署在各地边缘的服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，**使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率**

​		CDN是介于用户端的浏览器和服务端nginx回源地址源站之间的代理层，既充当了用户浏览器的服务端，又作为源站的服务器的客户端的角色。	

## DNS用CNAME解析到源站

用CDN来代理我们的静态资源文件。架构图：

![](images/QQ截图20201003140618.png)

DNS用CNAME解析到源站流程：

​		用户访问ecs服务器，服务器解析域名（DNS）将请求代理给离用户最近的CDN加速结点上，查询当前CDN结点上是否有相应的数据，如果没有则回源请求到服务器，并将数据缓存到CDN结点，下次访问直接从CDN结点中返回。提高访问速率

## 回源缓存设置

### cache-control

cache-control的值：

- private:客户端可以缓存
- public:客户端和代理服务器都可以缓存
- max-age=xxX∶缓存的内容将在xxx秒后失效
- **no-cache:强制向服务端再验证一次**
- no-store:不缓存请求的任何返回内容

参数的设置规则：

![](images/QQ截图20201003141706.png)

no-cache:强制向服务端再验证一次，验证的是当前缓存有效性的判断。

- ETag：资源的唯一标识

- If-None-Match:客户端发送的匹配Etag标识符
- Last-modified:资源最后被修改的时间
- If-Modified-Since:客户端发送的匹配资源最后修改时间的标识符（若If-Modified-Since晚于Last-modified则证明资源是有效的）

优先判断ETag：服务器第一次返回给客户端的数据鞋带上ETag的唯一标识，下一次不会请求具体的响应，而是发送验证请求，此时会带上ETag，服务器拿到请求的ETag和服务器本地文件的ETag值进行比较，如果比较结果是一致的就返回304Not Modified，表示该客户端的内容时有效的，

没有ETag，判断Last-modified

用户发起请求到CDN的流程，缓存协商逻辑：

![](images/QQ截图20201003143208.png)

返回304，直接读取本地缓存，如果返回200，则需要再访问一次服务器更新数据



### 浏览器的三种刷新方式

1. 回车刷新或a链接:看cache-control对应的max-age是否仍然有效，有效则直接from cache，若cache-control中为no-cache，则进入缓存协商逻辑
2. F5刷新或command+R刷新:去掉cache-control中的max-age或直接设置max-age为0，然后进入缓存协商逻辑

3. ctrl+F5或commond+shift+R刷新:去掉cache-control和协商头，强制刷新

**==协商机制，比较Last-modified和ETag到服务端，若服务端判断没变化则304不返回数据，否则200返回数据==**

![](images/QQ截图20201003144618.png)

### CDN自定义缓存策略

CDN中可以在控制台中自定义缓存策略：

- 可自定义目录过期时间
- 可自定义后缀名过期时间
- 可自定义对应权重（比如目录与后缀名冲突，按照权重选择）
- 可通过界面或api强制cdn对应目录刷新（非保成功）	

**阿里云CDN配置的规则**：

![](images/QQ截图20201003145908.png)

总结：源站没有配置，遵从阿里云自己的，如果源站有配置，则看控制台中是否进行配置，如果没有则遵循源站的配置



## 静态资源部署策略

### 摘要部署

cssjs,img等元素使用摘要做文件名部署,例如45edw.js（用版本号作为文件名）,新老版本并存且可回滚，资源部署完后再部署html

### 声明周期部署策略

1、对于静态资源保持声明周期内不会变，max-age可以设置的很长，无视失效更新周期

2、html文件设置no-cache或较短的max age，以便于更新

3、html文件仍然可以设置很长的max age，依靠一个动态获取版本号的请求发送到后端，异步下载最新版本号的html后展示渲染在前端（较好的html部署方案）

### 动态请求静态化

1、动态请求也可以静态化成json资源推送到CDN上，但是存在热点更新的问题，用户先拿到CDN上的资源，然后发送一个异步请求，不获取具体内容，仅仅比对版本号，若不匹配，再向源站发送一个获取最新内容的请求，并且覆盖上页面的内容。

2、若需要做紧急下架处理，可以依靠异步请求获取后端结点对应资源的状态，如果判断是被下架的状态，立马将页面进行覆盖

3、可通过跑批紧急推送cdn内容以使其下架等操作

## 全页面静态化技术

既然我们的静态资源css,img,js...和动态请求都可以cdn化，那么为什么不将他们合二为一，也就有了全页面静态化技术。

**定义：**

在服务端完成html、css、甚至js的load渲染成纯html文件后直接以静态资源的方式部署到cdn上

**使用：**

phantomjs：无头浏览器，可以借助其模拟webkit js的执行

修改需要全页面静态化的实现，采用initView和hasInit方式防止多次初始化



1）修改getitem.html文件，添加isInit标志位

```html
<body>
	<input type="hidden" id="isInit" value="0" />
</body>
<script>
function hasInit(){
	var isInit = $("#isInit").val();
	return isInit;
}
function setHasInit(){
	$("#isInit").val("1");
}

function initView(){
	var isInit = $("#isInit").val();
	if(isInit == "1"){
		return;
	}
	//获取商品详情
	$.ajax({
		type:"GET",
		url:"http://"+g_host+"/item/get",
		data:{
			"id":getParam("id"),
		},
		xhrFields:{withCredentials:true},
		success:function(data){
			if(data.status == "success"){
				g_itemVO = data.data;
				reloadDom();
				setInterval(reloadDom,1000);
				setHasInit();//完成后将标志位设为1，避免重复访问服务器
			}else{
				alert("获取信息失败，原因为"+data.data.errMsg);
			}
		},
		error:function(data){
			alert("获取信息失败，原因为"+data.responseText);
		}
	});
}
</script>
```

2）编写phantomJs文件，将动态请求与静态资源渲染后返回一个html

```js
var page = require('webpage').create();
var fs = require("fs");
page.open("http://miaoshaserver.com/resources/getitem.html?id=6"
	,function(status){
		console.log("status = " +status);
		var isInit = "0";
		setInterval(function(){
			if(isInit != "1"){//尝试判断是否已经渲染，如果没有每1秒钟进行判断
				page.evaluate(function(){
					initView();
				});
				isInit = page.evaluate(function(){
					return hasInit();
				})
			}else{
                //直到渲染成功后返回一个静态的html文件
				fs.write("getitemphantom.html",page.content,"w");
				phantom.exit();
			}
		},1000);
	});
```

可以将静态页面生成后推送到CDN上。

# 交易性能优化之缓存库存

## 交易性能瓶颈

1、交易验证完全依赖数据库

2、库存行锁

3、后置处理逻辑

## 优化

1、将检验下单状态操作和用户信息验证的操作放入缓存中进行，减轻数据库的压力



2、扣减库存优化

​	因为在数据库中扣减库存，对此此磁盘的操作性能开销较大，可以将库存的扣减放到缓存中进行，相比于对磁盘的操作性能更高

​	步骤：

​	1）活动发布同步库存进缓存

​	2）下单交易减库存（串行化）

​	3）异步消息同步数据库记录



3、rocketmq引入

工作流程：

![](images/QQ截图20201004102411.png)

broker中存放多个队列或主题，broker启动时会向NameServer进行注册，并保持长连接（心跳机制），Producer从NameServer中发现Broker的ip地址或负责的主题、队列，然后将生产的消息投放到对应的主题或队列中；Comsumer_group也会从NameServer中获取Broker的信息，并且与Broker**保持长连接**，监听是否有可用的消息，

每个Comsumer_Group中的Comsumer不会消费到相同的消息，不同的Comsumer_Group可以对同一条信息进行消费

一般而言Comsumer_Group中的每个Consumer监听Broker中的一个queue/toppic因此queue的数量最好与Consumer的数量保持一致

Broker也可以做主从的复制，主从之间的数据同步方式是可以选择的（同步、异步），为了性能考虑，一般选择异步同步数据，因此，当Broker1发生故障时，NameServer会实时感知到并且将Broker2重新作为主，此时如果是异步同步数据的话，可能会导致少量数据丢失。

4、分布式事务的选择：

在分布式系统中，会优先满足AP原则（如果没有可用性，那么一切都是空话），那么意味着数据的一致性并不是瞬时完成的，那么就有BASE柔性事务的概念，我们只要求**数据的最终一致性**

![](images/QQ截图20201004103446.png)



rocketmq运行：

```shell
#在conf/broker.conf文件中配置
brokerIP1=192.168.242.133
#启动nameserver
nohup sh bin/mqnamesrv &
#查看是否启动成功
tail -f ~/logs/rocketmqlogs/namesrv.log
#启动broker
nohup sh bin/mqbroker -n 192.168.242.133:9876 -c conf/broker.conf &
#查看broker是否启动成功
tail -f ~/logs/rocketmqlogs/broker.log 
#创建topic
./mqadmin updateTopic -n localhost:9876 -t stock -c DefaultCluster
```



代码实现下单扣减缓存库存，发送异步消息执行扣减数据库的操作

Producer

```java
@Component
public class MqProducer {

    private DefaultMQProducer producer;
    @Value("${mq.nameserver.addr}")
    private String nameAddr;
    @Value("${mq.topicname}")
    private String topicName;

    @PostConstruct
    public void init() throws MQClientException {
        //mq Producer的初始化
        producer = new DefaultMQProducer("producer_group");
        producer.setNamesrvAddr(nameAddr);
        producer.start();
    }
    //同步扣减库存
    public boolean asyncReduceStock(Integer itemId, Integer amount){
        Map<String,Object> map = new HashMap<>();
        map.put("itemId", itemId);
        map.put("amount", amount);
        Message message = new Message(topicName, "increase",
                JSON.toJSON(map).toString().getBytes(Charset.forName("UTF-8")));
        try {
            producer.send(message);
        } catch (MQClientException e) {
            e.printStackTrace();
            return false;
        } catch (RemotingException e) {
            e.printStackTrace();
            return false;
        } catch (MQBrokerException e) {
            e.printStackTrace();
            return false;
        } catch (InterruptedException e) {
            e.printStackTrace();
            return false;
        }
        return true;
    }
}
```

Consumer:

```java
@Component
public class MqConsumer {

    private DefaultMQPushConsumer consumer;

    @Value("${mq.nameserver.addr}")
    private String nameAddr;
    @Value("${mq.topicname}")
    private String topicName;
    @Autowired
    private ItemStockDOMapper itemStockDOMapper;

    @PostConstruct
    public void init() throws MQClientException {
        consumer = new DefaultMQPushConsumer("stock_consumer_group");
        consumer.setNamesrvAddr(nameAddr);
        consumer.subscribe(topicName, "*");
        consumer.registerMessageListener(new MessageListenerConcurrently() {
            @Override
            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext consumeConcurrentlyContext) {
                //实现库存的真正删减
                byte[] body = msgs.get(0).getBody();
                Map<String, Object> map = JSON.parseObject(new String(body), Map.class);
                Integer itemId = (Integer) map.get("itemId");
                Integer amount = (Integer) map.get("amount");
                itemStockDOMapper.decreaseStock(itemId, amount);
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });
        consumer.start();
    }
}
```

减库存操作：

```java
	@Override
    @Transactional
    public boolean decreaseStock(Integer itemId, Integer amount) throws BusinessException {
//        int affectedRow =  itemStockDOMapper.decreaseStock(itemId,amount);
        //减掉缓存中的库存信息
        long result = redisTemplate.opsForValue().
                        increment("promo_item_stock_" + itemId, amount.intValue() * -1);

        if (result >= 0) {
            //异步消息扣减数据库
            boolean flag = producer.asyncReduceStock(itemId, amount);
            if (!flag) {
                //如果失败，需要回补库存
                redisTemplate.opsForValue().increment("promo_item_stock_" + itemId, amount.intValue());
                return false;
            }
            //更新库存成功
            return true;
        } else {
            //更新库存失败
            redisTemplate.opsForValue().increment("promo_item_stock_" + itemId, amount.intValue());
            return false;
        }
    }
```

存在问题：

​		同步数据的过程中如果出现问题怎么办？

​		消息发出去了，但是业务发生异常回滚了，如何让消息也进行回滚？



# 交易性能优化之事务型消息

上面的异步消息存在问题，若整个事务在发送完消息之后进行回滚，那么就会导致缓存和数据中的数据不一致了！

可以将异步消息的发送延迟了整个事务提交成功之后进行，但是同时有存在问题：如果等到事务提交成功后再发送异步消息，那么这个消息只能成功，因为没有失败后的处理了。

解决：事务型消息

## 事务型消息

事务型消息的工作流程：

​		1、事务型消息发送后，消息会被投放到broker中，但是出于prepare阶段，消费者是不可见的。也就无法消费

​		2、然后会调用TransactionListener的executeLocalTransaction方法，在这里我们自定义我们要执行的方法，该方法的返回值决定，此次投递的消息的状态是COMMIT，ROLLBACK还是继续UNKNOW

​		3、如果executeLocalTransaction长时间没有返回（执行比较耗时的操作），或者返回的UNKNOW，那么隔消息中间件会回调checkLocalTransaction方法来判断这个消息的状态。

**业务中的应用：**

引入事务型消息，在发送消息后根据创建订单的状态的来决定此事务型消息是否应该提交，或是继续等待，在executeLocalTransaction执行时间较长或者返回过程中丢失的情况下，**我们还应该引入库存流水，方便异步消息回调的方法能实时感知订单处理的状态**。

```java
transactionMQProducer.setTransactionListener(new TransactionListener() {
            //将消息投递后随即调用该方法
            @Override
            public LocalTransactionState executeLocalTransaction(Message message, Object arg) {
                //在这里执行创建订单的操作，这里执行的结果决定了消息是否可以被消费
                Map<String, Object> map = (Map) arg;
                Integer userId = (Integer) map.get("userId");
                Integer promoId = (Integer) map.get("promoId");
                Integer itemId = (Integer) map.get("itemId");
                Integer amount = (Integer) map.get("amount");
                String stockLogId = (String) map.get("stockLogId");
                try {
                    orderService.createOrder(userId,itemId,promoId,amount,stockLogId);
                } catch (BusinessException e) {
                    e.printStackTrace();
                    //发生异常，更改订单状态
                    StockLogDO stockLogDO = stockLogDOMapper.selectByPrimaryKey(stockLogId);
                    stockLogDO.setStatus(3);
                    stockLogDOMapper.updateByPrimaryKeySelective(stockLogDO);
                    return LocalTransactionState.ROLLBACK_MESSAGE;
                }
                return LocalTransactionState.COMMIT_MESSAGE;
            }
            //当executeLocalTransaction长时间没有返回结果或返回UNKNOW，那么消息中间件就会回调这个方法
            @Override
            public LocalTransactionState checkLocalTransaction(MessageExt messageExt) {
                //根据是否扣减库存成功，来判断是否要返回COMMIT，ROLLBACK还是继续UNKNOW
                byte[] body = messageExt.getBody();
                Map<String,Object> map = JSON.parseObject(new String(body), Map.class);
                String stockLogId = (String) map.get("stockLogId");
                StockLogDO stockLogDO = stockLogDOMapper.selectByPrimaryKey(stockLogId);
                if (stockLogDO == null) {
                    return LocalTransactionState.UNKNOW;
                }
                Integer status = stockLogDO.getStatus();
                if (status.intValue() == 2) {
                    return LocalTransactionState.COMMIT_MESSAGE;
                }else if (status.intValue() == 1) {
                    return LocalTransactionState.UNKNOW;
                }else{
                    return LocalTransactionState.ROLLBACK_MESSAGE;
                }
            }
        });


//事务型同步库存扣减消息
    public boolean transactionAsyncReduceStock(Integer userId, Integer itemId, Integer promoId, Integer amount, String stockLogId){
        Map<String,Object> map = new HashMap<>();
        map.put("itemId", itemId);
        map.put("amount", amount);
        map.put("stockLogId", stockLogId);
        Message message = new Message(topicName, "increase",
                JSON.toJSON(map).toString().getBytes(Charset.forName("UTF-8")));
        HashMap<String, Object> argsMap = new HashMap<>();
        argsMap.put("itemId", itemId);
        argsMap.put("amount", amount);
        argsMap.put("userId", userId);
        argsMap.put("promoId", promoId);
        argsMap.put("stockLogId", stockLogId);
        TransactionSendResult transactionSendResult = null;
        try {
            //发会将消息投递到broker中但是是处于prepare阶段，消费者不可见，在客户端执行executeLocalTransaction方法
            transactionSendResult = transactionMQProducer.sendMessageInTransaction(message,argsMap);
        } catch (MQClientException e) {
            e.printStackTrace();
            return false;
        }
        if (transactionSendResult.getLocalTransactionState() == LocalTransactionState.COMMIT_MESSAGE) {
            return true;
        }else{
            return false;
        }
    }
```



## 业务场景决定高可用技术

在分布式系统中，我们很难保证所有请求都能以最佳的用户体验返回，因此我们可以在柔性事务，最终一致性的前提下，根据我们的业务场景来决定高可用技术。

比如我们的设计原则是：

	- 宁可少买，不能超卖

方案：

	- redis中的数据可以比实际数据库中少
	- 超时释放



## 库存售罄处理方案

在秒杀系统中，可能同一时间会有上万个请求进来购买某个商品，但实际上可用的库存只有几百个，那么没有必须为每个请求分配流水去判断是否还有库存，而是应该在售罄之后直接打上售罄标识（打到内存或者缓存），后面的请求不进行处理，直接返回。

**库存售罄模型:**

- 库存售罄标识
- 售罄后不去操纵后序流程
- 售罄后通知各系统售罄
- 回补上新



这里当售罄后直接在redis中打上库存售罄的标识，每次处理之前进行判断，避免执行费操作

```java
 @Override
    @Transactional
    public boolean decreaseStock(Integer itemId, Integer amount) throws BusinessException {
//        int affectedRow =  itemStockDOMapper.decreaseStock(itemId,amount);
        //减掉缓存中的库存信息
        long result = redisTemplate.opsForValue().
                        increment("promo_item_stock_" + itemId, amount.intValue() * -1);

        if (result > 0) {
            //更新库存成功
            return true;
        }else if (result == 0) {
            //打上库存售罄标识
            redisTemplate.opsForValue().set("promo_item_stock_invalid"+itemId,"true");
            return true;
        } else {
            //更新库存失败
            redisTemplate.opsForValue().increment("promo_item_stock_" + itemId, amount.intValue());
            return false;
        }
    }

//ordercontroller
 		//判断库存是否售罄
        if (redisTemplate.hasKey("promo_item_stock_invalid"+itemId)) {
            throw new BusinessException(EmBusinessError.STOCK_NOT_ENOUGH);
        };
```



## 后置流程

销量逻辑化

交易单逻辑异步化（假异步，支付需要等待交易单生成，不推荐）



# 流量削峰技术

## 秒杀令牌

**为什么要引入秒杀令牌？**

因为秒杀验证逻辑和下单接口应该解耦，他们之间通过秒杀令牌进行关联，也就是下单接口只需要验证秒杀令牌是否合法即可。

**秒杀令牌原理**

- 秒杀接口需要令牌才能进入
- 秒杀令牌由秒杀活动模块负责生成
- 秒杀活动模块对秒杀令牌的生成全权负责。逻辑收口



秒杀令牌的生成：秒杀令牌的值应该是一个字符串（UUID），key根据活动的id、用户的id、商品的id三个维度来生成。

流程：秒杀商品时，客户端先发送请求秒杀令牌，服务端验证用户信息、活动信息和商品信息，如果合法则生成秒杀令牌并返回，客户端再拿着获取到的秒杀令牌进行下单操作。

## 秒杀大闸

面对大流量的涌入，我们不应该对所有的请求都分发秒杀令牌，造成系统的压力，我们可以**通过对秒杀令牌数量的限制来控制限制进入系统的流量。**

原理：

- 依靠秒杀令牌的授权原理定制化发牌逻辑，做到大闸功能
- 根据秒杀商品初始库存颁发对应数量令牌，控制大闸流量（发布活动信息时）
- 用户风控策略前置到秒杀令牌发放中
- 库存售罄判断前置到秒杀令牌发放中

但是仍然存在以下缺陷

- 浪涌流量涌入后系统无法应对（当某款火爆商品的库存有上十万件后，即使根据库存*1的秒杀大闸也是对系统的极大消耗）
- 多库存，多商品等令牌限制能力弱

## 队列泄洪

### 原理：

1、排队有时候比并发更加高效（例如redis单线程，innodb mutex key等）

​		当大量线程并发访问资源时，存在着锁竞争的问题，遇到锁需要阻塞，等待锁释放后再被唤醒继续下一次的争抢锁的过程，当大量线程涌入时，**CPU会花费大量的时间在线程的调度上**。有锁是因为多个线程同时访问资源，可能会造成数据的不一致。那么我们让线程排队一个一个地执行是否就不需要锁了呢，对应的CPU的在线程之间调度的资源也就省略了，而且它的执行时间也是恒定的。		例如redis就是使用的单线程的模型，但是它仍然十分的高效：

​			1）因为它是基于内存的，它的set操作，只需要对应的json序列set到内存中，然后直接返回，不会有阻塞操作

​			2）单线程模型，它没有CPU切换上下文的开销，运维很多时候都会将redis的执行绑定到一个固定的CPU上，也就是说这个CPU只用来做redis，那就更好了，连线程上下文的开销都没有了

​		还有AliSql，保证对外的jdbc的接口不变，当判断到有n多个线程要来竞争同一个主键id的mutex key的时候，mysql就在内存中维护一个队列，将这些线程发来的sql语句都在这个队列里面排队，然后在队列的另一端依次取出对应的SQL语句进行操作，通过改变mysql内部序列的执行方式来解决mutex key竞争的额问题

​		**那么什么时候排队比并发的执行效率更高？**

​				当多个线程执行的操作大部分相同，并且他们之间存在锁的竞争关系的时候，队列的效率更高

​				当多个线程执行的操作只有小部分之间存在锁的竞争关系，那么并发的效率更高。

​				我们需要根据不同的业务场景去进行合理的选择。

2、依靠排队去限制并发流量

3、依靠排队和下游拥塞窗口程度调整队列释放流量的大小

​		支付宝银行网关队列距离，支付宝的上亿的TPS和银行几千的TPS之间就是通过调整下游拥塞窗口，来调整队列释放流量的大小。

## 使用线程池完成队列泄洪

将检验秒杀令牌和异步创建订单的操作放到线程池中同步处理。

```java
//同步调用线程池的submit方法
        //拥塞窗口为20的等待队列，用来队列泄洪
        Future<Object> future = executorService.submit(new Callable<Object>() {
            @Override
            public Object call() throws Exception {
                //初始化库存流水
                String stockLogId = itemService.initStockLog(itemId, amount);

                //        OrderModel orderModel = orderService.createOrder(userModel.getId(),itemId,promoId,amount);
                //事务型消息创建订单
                if (!producer.transactionAsyncReduceStock(userModel.getId(), itemId, promoId, amount, stockLogId)) {
                    throw new BusinessException(EmBusinessError.UNKNOWN_ERROR, "下单失败");
                }
                return null;
            }
        });

        try {
            future.get();//block自己等待返回
        } catch (InterruptedException e) {
            throw new BusinessException(EmBusinessError.UNKNOWN_ERROR);
        } catch (ExecutionException e) {
            throw new BusinessException(EmBusinessError.UNKNOWN_ERROR);
        }
        return CommonReturnType.create(null);
```

**本地or分布式的泄洪**

本地：将队列维护在本地内存

分布式：将队列设置到外部redis中

两种方式都各有利弊：

​	采用分布式的队列，我们可以集中管理整个分布式系统的队列的状态，但是它存在单点故障问题，并且在redis中进行操作，会有额外的网络流量的性能开销，并且要对redis产生对应的负载。它会变成系统的瓶颈

​	采用本地的队列，不需要进行走网络流量的开销，而且具有集群部署具有高可用性。缺点就是，不能集中化管理，需要使用负载均衡的策略将请求均匀的分布到每个结点。

​	生成环境中最好的方案是：先使用redis的队列泄洪，当大量流涌入，导入redis负载过大时。采用降级策略，使用本地队列进行泄洪



# 防刷限流技术

## 验证生成与验证技术

在发送下单请求之前先发送请求获取去验证码，并且将生成的验证码放入redis中进行存储。

在生成令牌之前先进行验证码的校验，防止脚本进行刷单

```java
 @RequestMapping(value = "/generateverifycode", method = {RequestMethod.GET})
    @ResponseBody
    public void generateverifycode(HttpServletResponse response) throws BusinessException, IOException {
        //根据token获取用户信息
        String token = httpServletRequest.getParameter("token");
        if (token == null) {
            throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登陆，不能下单");
        }
        System.out.println("获取的token：" + token);
        //获取用户的登录信息
        UserModel userModel = (UserModel) redisTemplate.opsForValue().get(token);
        if (userModel == null) {
            throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登陆，不能下单");
        }
        Map<String,Object> map = CodeUtil.generateCodeAndPic();
        redisTemplate.opsForValue().set("verify_code_"+userModel.getId(),map.get("code"));
        ImageIO.write((RenderedImage) map.get("codePic"), "jpeg", response.getOutputStream());
    }

    //生成秒杀令牌
    @RequestMapping(value = "/generatetoken", method = {RequestMethod.POST}, consumes = {CONTENT_TYPE_FORMED})
    @ResponseBody
    public CommonReturnType generatetoken(@RequestParam(name = "itemId") Integer itemId,
                                          @RequestParam(name = "promoId") Integer promoId,
                                          @RequestParam(name = "verifyCode") String verifyCode) throws BusinessException {
        //根据token获取用户信息
        String token = httpServletRequest.getParameter("token");
        if (token == null) {
            throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登陆，不能下单");
        }
        System.out.println("获取的token：" + token);
        //获取用户的登录信息
        UserModel userModel = (UserModel) redisTemplate.opsForValue().get(token);
        if (userModel == null) {
            throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登陆，不能下单");
        }
        //对验证码进行判断
        String verifyCodeInRedis = (String) (redisTemplate.opsForValue().get("verify_code_" + userModel.getId()));
        if (!StringUtils.equalsIgnoreCase(verifyCodeInRedis, verifyCode)) {
            throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR,"验证码错误");
        }


        //生成秒杀令牌
        String promoToken = promoService.generateSecondKillToken(promoId, userModel.getId(), itemId);
        if (promoToken == null) {
            throw new BusinessException(EmBusinessError.PARAMETER_VALIDATION_ERROR, "生成令牌失败");
        }
        return new CommonReturnType().create(promoToken);
    }
```

## 掌握限流原理及实现

## 限流方案

**限并发**

根据TPS/QPS，自定义一个计数器进行限制

**令牌桶算法**

通过计时器每秒往桶中防止指定数量的令牌，客户端访问接口时先尝试从桶中获取令牌，只有获取到令牌的请求才能执行后序的操作。这样就可以将接口的流量限制在一个恒定的TPS/QPS，保持系统的稳定性。

![](images/QQ截图20201005201315.png)

**漏桶算法**

桶中有指定数量的水（请求），每秒以恒定的速率流出，每次请求相当于向桶中加入一滴水，桶满了之后则无法再处理请求。同样达到了限流的目的。

![](images/QQ截图20201005201824.png)

**两者算法的区别**

漏桶算法用来平滑网络流量以固定的速率流入对应的接口，令牌桶算法是用来限制某一秒的流量的最大值，可以应对一些突发的流量，但是不能超过限定的值。

**秒杀系统中主要还是用令牌桶算法为主，因为我们需要处理突发的流量。**

## 项目中使用自定义注解无侵入对接口进行限流

```java
@Retention(RetentionPolicy.RUNTIME)
@Target(ElementType.METHOD)
public @interface AccessLimit {
    int second();
    int maxCount();
}
```

将该注解添加在需要限流的接口上，将限流逻辑与业务逻辑进行解耦。然后在拦截器中做限流的处理。

```java
@Component
public class AccessInterceptor implements HandlerInterceptor {
    @Autowired
    RedisTemplate redisTemplate;

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {

        if (handler instanceof HandlerMethod) {
            //根据token获取用户信息
            String token = request.getParameter("token");
            if (token == null) {
                throw new BusinessException(EmBusinessError.USER_NOT_LOGIN, "用户还未登陆，不能下单");
            }
            System.out.println("获取的token：" + token);
            //获取用户的登录信息
            UserModel userModel = (UserModel) redisTemplate.opsForValue().get(token);
            if (userModel == null) {
                render(response,"用户未登录，请先登录");
                return false;
            }
            //将用户信息放入到ThreadLocal中保存
            UserContext.setHolder(userModel);

            HandlerMethod handlerMethod = (HandlerMethod) handler;
            AccessLimit accessLimit = handlerMethod.getMethodAnnotation(AccessLimit.class);
            if (accessLimit == null) {
                return true;
            }
            int second = accessLimit.second();
            int maxCount = accessLimit.maxCount();
            //通过redis来做接口的限流，可以替换成guava的RateLimiter
            String uri = request.getRequestURI();
            String uriKey = uri + "_" + token;
            Integer count = (Integer) redisTemplate.opsForValue().get(uriKey);
            if (count == null) {
                redisTemplate.opsForValue().set(uriKey, 1, second, TimeUnit.SECONDS);
            } else if (count < maxCount) {
                redisTemplate.opsForValue().increment(uriKey, 1);
            } else {
                render(response,"访问太频繁，请稍后再试");
                return false;
            }
        }
        return true;
    }
    public void render(HttpServletResponse response,String msg) throws IOException {
        response.setContentType("application/json;charset=UTF-8");
        OutputStream outputStream = response.getOutputStream();
        outputStream.write(msg.getBytes("UTF-8"));
        outputStream.flush();
        outputStream.close();
    }
//    public void render1(HttpServletResponse response, EmBusinessError error) throws IOException {
//        response.setContentType("application/json;charset=UTF-8");
//        OutputStream outputStream = response.getOutputStream();
//        Map<String,Object> responseData = new HashMap<>();
//        responseData.put("errCode",error.getErrCode());
//        responseData.put("errMsg",error.getErrMsg());
//        String resp = JSON.toJSONString(CommonReturnType.create(responseData, "fail"));
//        outputStream.write(resp.getBytes("UTF-8"));
//        outputStream.flush();
//        outputStream.close();
//    }
}
```

将用户信息放在ThreadLocal中保存，既能不用将参数层层传递，又可以保证线程安全。

```java
public class UserContext {
    private static ThreadLocal<UserModel> holder = new ThreadLocal<>();

    public static UserModel getHolder() {
        return holder.get();
    }

    public static void setHolder(UserModel userModel) {
        holder.set(userModel);
    }
}
```





## 限流的范围

- 集群限流∶依赖redis或其他的中间件技术做统一计数器，往往会产生性能瓶颈
- 单机限流:负载均衡的前提下单机平均限流效果更好

## 防黄牛技术

排队，限流，令牌均只能控制总流量，无法控制黄牛流量

## 传统防刷

限制一个会话(session_id,token)同一秒钟/分钟接口调用多少次:多会话接入绕开无效

限制一个ip同一秒钟/分钟接口调用多少次∶数量不好控制，容易误伤

## 黄牛为什么难防

- 模拟器作弊∶模拟硬件设备，可修改设备信息
- 设备牧场作弊:工作室里一批移动设备
- 人工作弊:靠佣金吸引兼职人员刷单

## 设备指纹

- 采集终端设备各项参数，启动应用时生成唯一设备指纹
- 根据对应设备指纹的参数猜测出模拟器等可疑设备概率

## 凭证系统（推荐）

- 根据设备指纹下发凭证
- 关键业务链路上带上凭证并由业务系统到凭证服务器上验证
- 凭证服务器根据对应凭证所等价的设备指纹参数并根据实时行为风控系统判定对应凭证的可疑度分数
- 若分数低于某个数值则由业务系统返回固定错误码，拉起前端验证码验身（短信验证......），验身成功后加入凭证服务器对应分数























